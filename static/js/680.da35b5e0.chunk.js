"use strict";(self.webpackChunkreact_app=self.webpackChunkreact_app||[]).push([[680],{3253:function(e,t,i){i.r(t),i.d(t,{ExperienceContents:function(){return p},TalkRayTracing:function(){return d},default:function(){return l}});var r=i(4136),n=i(8641),a=i(9240),s=i(3471),o=i(2791),c=i(1482),h=i(184);function l(){return(0,o.useEffect)((function(){document.title="Experience - Peter HU"}),[]),(0,h.jsxs)(s.E.div,{children:[(0,h.jsx)(a.Z,{}),(0,h.jsx)(r.Z,{}),(0,h.jsx)("h2",{children:(0,h.jsx)("b",{children:"EXPERIENCE"})}),(0,h.jsx)(p,{showall:!0}),(0,h.jsx)(n.Z,{})]})}function d(e){return 1==e.showall?(0,h.jsxs)(h.Fragment,{children:["Sharing session of my industry research topic on ",(0,h.jsx)("i",{children:"Ray Tracing (Intersection, Acceleration)."}),"  ",(0,h.jsx)("br",{}),"Presented both internally and at university. \xa0 | \xa0  ",(0,h.jsx)("a",{href:"./asset/doc/RT_Peter-v6.pdf",children:"Slides"}),"   ",(0,h.jsx)("br",{}),(0,h.jsx)("embed",{src:"./asset/doc/RT_Peter-v6.pdf",width:"92%",height:"300px"}),(0,h.jsxs)("div",{class:"announcement",children:[(0,h.jsx)("b",{children:"Talk: "}),"Speeding up real-time Ray Tracing @ ",(0,h.jsx)("a",{href:"https://kudos.chu.cam.ac.uk/talks/about",children:"Churchill College Tech talk"})," | Date:  ",(0,h.jsx)("i",{children:"Nov 1, 2023"}),(0,h.jsx)("br",{}),(0,h.jsx)("b",{children:"Feedback:"}),(0,h.jsx)("i",{children:'"You managed to give a very broad overview of a wide range of techniques used to speed up ray tracing."'}),(0,h.jsx)("br",{}),(0,h.jsx)("i",{children:'"Very rich and complex concepts that cover graphics pipeline rendering in depth. Discussed design tradeoffs and current directions of research."'}),(0,h.jsx)("br",{}),(0,h.jsx)("i",{children:'"Beautiful video to demonstrate why we want ray tracing, useful pictures and diagrams throughout to explain ideas, introduced a lot of steps in the pipeline where I can see some of it being used outside graphics."'}),(0,h.jsx)("br",{})]})]}):null}function u(e){return 1==e.showall?(0,h.jsxs)(h.Fragment,{children:[(0,h.jsx)("embed",{src:"https://peterhuistyping.github.io/CPU_Scheduling_Review/",width:"90%",height:"300px"}),(0,h.jsx)("br",{})]}):null}function p(e){return(0,h.jsx)("div",{class:"content",children:(0,h.jsxs)(h.Fragment,{children:[(0,h.jsx)("i",{children:"May, 2023 - Jan, 2024"})," |  ",(0,h.jsx)("a",{href:"https://www.cambridgesciencepark.co.uk/",children:"Industry Research center, Cambridge Science Park"}),", UK.",(0,h.jsx)("br",{}),(0,h.jsx)("br",{}),"We explore various architectural and algorithmic innovations towards the next-generation mobile or cloud based processors (CPU, GPU, NPU). During these period of time, I am also exposed to other research summits or events hosted, including talks and connections with other academic professors and industry experts. The topics discussed range from the above to more, such as simulation, LLM, compiler and federated learning, which I enjoy the most.",(0,h.jsx)("br",{}),"  ",(0,h.jsx)("br",{}),"In particular, I focus on Ray Tracing acceleration via classical graphics and machine learning techniques, under supervision of senior engineers and Mathematics graduates. During which, I maintain and develop a open-source research ",(0,h.jsx)("a",{href:"https://github.com/knightcrawler25/GLSL-PathTracer",children:"GLSL path renderer"})," in C and GLSL. With the renderer setup, I redesign the underlying BVH algorithms, keeping balance between preprocessing time and real-time intersection complexity. One of our proposed methods are deployed in the product and thus received research-center-wise award.  Besides, we also explore various possibilities of combining AI / machine learning with graphics task, including Ambient Occlusion or Global illumination, which I help integrate the renderer and Pytorch training pipeline, as part of the research explorations.",(0,h.jsx)("br",{}),(0,h.jsx)("br",{}),(0,h.jsxs)("center",{children:[(0,h.jsx)("img",{width:"120vw",src:"asset/photo/experience/RT/AO_64spp.png",alt:"AO-64spp",title:"AO-64spp"}),(0,h.jsx)("img",{width:"120vw",src:"asset/photo/experience/RT/baryMap.png",alt:"baryCenter",title:"baryCenter"}),(0,h.jsx)("img",{width:"120vw",src:"asset/photo/experience/RT/colorMap.png",alt:"color",title:"color"}),(0,h.jsx)("img",{width:"120vw",src:"asset/photo/experience/RT/depthMap.png",alt:"depth",title:"depth"}),(0,h.jsx)("img",{width:"120vw",src:"asset/photo/experience/RT/normalMap.png",alt:"normal",title:"normal"}),(0,h.jsx)("img",{width:"120vw",src:"asset/photo/experience/RT/posMap.png",alt:"position",title:"position"}),(0,h.jsx)("br",{}),(0,h.jsx)("a",{href:"https://www.intel.com/content/www/us/en/developer/topic-technology/graphics-research/samples.html",children:"Sponza scene"})," from adapted ",(0,h.jsx)("a",{href:"https://github.com/knightcrawler25/GLSL-PathTracer",children:"GLSL path renderer"}),", forming ",(0,h.jsx)("a",{href:"https://en.wikipedia.org/wiki/Deferred_shading",children:"GBuffer"})," for further explorations."]}),(0,h.jsx)("br",{}),"Aside from that, I also join the CPU team on heterogeneous scheduling, DVFS and dynamic resource management, supervised by PhD graduate in Electrical Engineering and other engineers. I initialize the codebase for the scheduler simulator in Python, from which the team develop the prototype for the next-gen scheduling policies based on the literature review I collected. In general, the difficulty lies in the multi-objective optimization and tradeoff between performance, power consumption, thermal conditions, priorities, fairness and other factors.",(0,h.jsx)("br",{}),"  ",(0,h.jsx)("br",{}),(0,h.jsx)("i",{children:"For details, please click the 'Show Details' button."}),(0,h.jsx)("br",{}),(0,h.jsx)("br",{}),"Research Engineer Intern (",(0,h.jsx)("b",{children:"Graphics Algorithms / GPU Architecture"}),")  \xa0 \xa0 \xa0 ",(0,h.jsx)("i",{children:" 2023.5 - 2024.1"}),(0,h.jsx)("br",{}),(0,h.jsx)(c.H,{title:(0,h.jsxs)(h.Fragment,{children:["| ",(0,h.jsx)("a",{href:"./asset/doc/StarofCambridge.png",children:"Award"})," for new prediction algorithm proposed with joint efforts. | "," "]}),mainText:(0,h.jsxs)(h.Fragment,{children:[(0,h.jsx)("img",{width:"722",height:"705",src:"./asset/photo/Profile/GPU2.png",alt:"GPU2"}),(0,h.jsx)("br",{})]})}),(0,h.jsx)(d,{showall:e.showall}),(0,h.jsx)("br",{}),(0,h.jsx)("br",{}),"Research Intern (",(0,h.jsx)("b",{children:"CPU Architect"}),")  \xa0 \xa0  \xa0 \xa0   \xa0 \xa0  \xa0 \xa0 \xa0  \xa0 ",(0,h.jsx)("i",{children:"2023.6 - 2023.10"}),(0,h.jsx)("br",{}),(0,h.jsx)(c.H,{title:(0,h.jsxs)(h.Fragment,{children:[" | ",(0,h.jsx)("a",{href:"https://peterhuistyping.github.io/CPU_Scheduling_Review/",children:"Literature Review: Scheduling, DVFS, Dynamic Resource Management"})," \xa0|   "]}),mainText:(0,h.jsxs)(h.Fragment,{children:[(0,h.jsx)("img",{width:"671",height:"615 ",src:"./asset/photo/Profile/CPU.png",alt:"CPU"}),(0,h.jsx)("br",{})]})}),(0,h.jsx)("br",{}),(0,h.jsx)(u,{showall:e.showall}),(0,h.jsx)("br",{}),"Software Engineer Intern (",(0,h.jsx)("b",{children:"GPU"}),") \xa0 \xa0  \xa0 \xa0   \xa0 \xa0  \xa0 \xa0 \xa0  \xa0",(0,h.jsx)("i",{children:" 2022.12 - 2023.5 "}),"   ",(0,h.jsx)("br",{}),(0,h.jsx)(c.H,{title:(0,h.jsxs)(h.Fragment,{children:[" \xa0| \xa0 ",(0,h.jsx)("i",{children:"C++, Vulkan, GPU Driver, UE4 (rendering)"})]}),mainText:(0,h.jsxs)(h.Fragment,{children:[(0,h.jsx)("img",{width:"671",height:"276 ",src:"./asset/photo/Profile/GPU1.png",alt:"GPU1"}),(0,h.jsx)("br",{})]})}),(0,h.jsx)("br",{}),(0,h.jsxs)("i",{children:["Please refer to EXPERIENCE section in ",(0,h.jsx)("a",{href:"./asset/doc/CV_PeterHU.pdf",children:(0,h.jsx)("img",{width:"18vw",src:"./asset/photo/Logo/cv-blue.png",alt:"cv"})}),"."]}),(0,h.jsx)("br",{}),(0,h.jsx)("br",{})]})})}},5680:function(e,t,i){i.r(t),i.d(t,{FetchJourneyMainText:function(){return C},Publication:function(){return S},ResearchStory:function(){return I},default:function(){return P}});var r=i(1413),n=i(4925),a=JSON.parse('[{"pic1_src":"./asset/photo/pub/3/teaser.png","pic1_alt":"teaser","Title":"FreNBRDF: A Frequency-Rectified Neural Material Representation","Category":"","author":"Zheyuan Hu  \u2020, Chenliang Zhou * \u2020, Cengiz \xd6ztireli","Published":"IEEE International Workshop on Machine Learning for Signal Processing (MLSP), 2025.","Italic":"Computer Graphics (real-world materials), Frequency Rectification (Spherical Harmonics).","line":1,"Des1":"Evolved from my individual project in the [Machine Visual Perception](https://www.cl.cam.ac.uk/teaching/2425/MVP/) module (rank 2/15).","Time":"2024 - 2025","Arxiv":"https://arxiv.org/abs/2507.00476","PDF":"asset/photo/pub/3/FreNBRDF.pdf","Github":"https://github.com/Chenliang-Zhou/FrePolad","JourneyCategory":"my paper","Journey":"Supervised by my supervisor <a href=\\"https://chenliang-zhou.github.io/\\">Chenliang Zhou</a>, I investigate the frequency information of materials, i.e. BRDF, and how to utilize it in the material fitting, reconstruction and editing.  The first task is derived from a <a href=\\"https://doi.org/10.48550/arXiv.1703.06114\\">set encoder</a> with permutation invariance and flexibility of input size. Then, we measure its capability in material linear interpolation editing. <br/> We observe that the naive NBRDF autoencoder pipeline described above lacks the frequency information between the two NBRDFs, which might aid NBRDF weight distribution learning. I propose different methods to decompose BRDF three-dimensional inputs into those in unit sphere. Spherical harmonics is leveraged to express per-channel BRDF as a linear combination of orthonormal base functions, which captures the frequency information of BRDF.  <br/> This framework enhances fidelity, adaptability, and efficiency. Extensive experiments demonstrate that FreNBRDF improves the accuracy and robustness of material appearance reconstruction and editing compared to state-of-the-art baselines, enabling more structured and interpretable downstream tasks and applications."},{"pic1_src":"./asset/photo/pub/1/teaser.png","pic1_alt":"teaser","Title":"NeuMaDiff: Neural Material Synthesis via Hyperdiffusion","Category":"","author":"Chenliang Zhou *, Zheyuan Hu, Alejandro Sztrajman *, Yancheng Cai, Yaru Liu, Cengiz \xd6ztireli","line":1,"Des1":"Adapted from my undergrad [dissertation project](https://www.cst.cam.ac.uk/teaching/part-ii/projects) (93.5, rank 1/133).","Italic":"Computer Graphics (real-world materials), Vision (generation via PCA, VAE, diffusion).","Time":"2024 - 2025","Project":"https://github.com/peterhuistyping.github.io/NeuMaDiff/","Arxiv":"https://arxiv.org/abs/2411.12015","PDF":"https://arxiv.org/pdf/2411.12015","Github":"https://github.com/PeterHUistyping/NeuMaDiff","Dataset":"https://huggingface.co/datasets/Peter2023HuggingFace/NeuMERL","JourneyCategory":"my first paper","Journey":"Coauthored with my supervisors <a href=\\"https://chenliang-zhou.github.io/\\">Chenliang Zhou</a> and Dr <a href=\\"https://asztr.github.io/\\">Alejandro Sztrajman</a>, we together propose different aspects to the novel architecture, where I draw the network architecture via LaTeX <a href=\\"https://github.com/pgf-tikz/pgf\\">TikZ</a>. Our methods support the unconditional, statistically constrained and multi-modal generation of materials. With my experiments on PCA, VAE taking in either original or neural materials, we found out that hyperdiffusion has superiority in generating materials with high fidelity and diversity. <br/> Team up with Dr <a href=\\"https://asztr.github.io/\\">Alejandro Sztrajman</a>, we further explore and finalize the statistical constraints for each type of material, e.g. plastic, fabric, metallic, mirror-like, etc, based on observation and experiments. It serves as a classical, as well as ML-free way to classify the material. <br/> In particular, there is a lack of effective BRDF-space metrics in generation tasks, where we fill the gap through my experiments, targeting the diversity and fidelity with various underlying distance functions tried. Through literature review, I raise the idea of adapting point cloud based metrics to the field of materials. With further discussions with <a href=\\"https://chenliang-zhou.github.io/\\">Chenliang Zhou</a>, we finalize on which pairwise distance measurements to use. To further illustrate its effectiveness, I utilize the confusion matrix to demonstrate the evaluation process. With help of my plotted graph, it\'s clear that our methods are able to identify the relationship between reference and synthetic material sets. <br/> Finally, as a proof of concept, I setup some typical scenes using the proposed materials and render them with the physically-based renderer <a href=\\"http://www.mitsuba-renderer.org/\\">Mitsuba3</a>, which I writeup the BSDF class taking in the required binary format with proper importance sampling strategies (since there\'s no such public error-free implementation for Python version Mitsuba3).<br/> "},{"pic1_src":"./asset/photo/pub/2/teaser.png","pic1_alt":"teaser","Title":"CHOrD: Generation of Collision-Free, House-Scale, and Organized Digital Twins for 3D Indoor Scenes with Controllable Floor Plans and Optimal Layouts","Category":"","Italic":"Indoor Scene Synthesis, Generative Models, Digital Twin Generation.","author":"Chong Su \u2020, Yingbin Fu \u2020, Zheyuan Hu, Jing Yang, Param Hanji, Shaojun Wang, Xuan Zhao, Cengiz \xd6ztireli, Fangcheng Zhong *","Time":"2025.2","Arxiv":"https://arxiv.org/abs/2503.11958","PDF":"https://arxiv.org/pdf/2503.11958","More":"asset/photo/pub/2/InstructScene_CF_GISS.pdf","JourneyCategory":"collaborative","ShortTitle":"CHOrD: Generation of Collision-Free, ..., Digital Twins for 3D Indoor Scenes.","Journey":"Mentored by Dr <a href=\\"https://www.cl.cam.ac.uk/~fz261/\\">Fangcheng Zhong</a>, we investigated how 2D floor plans generation can be integrated with 3D indoor scene synthesis, for lower collision rate and higher fidelity.  In addition, a new real-world indoor scenes dataset will be released. <br/> I am responsible for reproducing the prior art <a href=\\"https://tangjiapeng.github.io/projects/DiffuScene/\\">DiffuScene, CVPR24</a> and <a href=\\"https://chenguolin.github.io/projects/InstructScene/\\"> InstructScene, ICLR24 Spotlight</a>. Meanwhile, I investigated the YOLO-v8 Oriented Bounding Box (OBB) <a href=\\"https://github.com/ultralytics/ultralytics/issues/15805\\">detection error</a> and proposed alternative methods, e.g. Rotated Bounding Box (RBB).<br/> The former <a href=\\"https://tangjiapeng.github.io/projects/DiffuScene/\\">DiffuScene</a> is based on applying diffusion model for parametrized objects (location, size, orientation, class, shape code). For greater instruction control, the latter <a href=\\"https://chenguolin.github.io/projects/InstructScene/\\"> InstructScene</a> follows a two-stage procedure. A semantic graph, with class label, (additional) pairwise spatial relationship and quantized features, is constructed from the prior semantic input. After that, a separate 3D decoder determines the exact layout (location, size, orientation). For details, please refer to <a href=\\"asset/photo/pub/2/InstructScene_CF_GISS.pdf\\" alt=\\"InstructScene_CF_GISS\\">retraining InstructScene on our CF-GISS dataset</a>. <br/>"}]'),s=i(5882),o=i(184);function c(){return(0,o.jsx)(s.ZP,{resource:a,display_type:"research"})}var h=i(8641),l=i(9240),d=i(3471),u=i(4136),p=i(2791),g=i(3253),f=i(1482),x=i(2260),m=i(4131),j=i(4713),b=i(2937),w=i(6557),y=["node"],v=["node"];function C(e){return(0,o.jsx)(x.U,{remarkPlugins:[m.Z,b.Z],rehypePlugins:[j.Z,w.Z],children:e.Journey,components:{img:function(e){e.node;var t=(0,n.Z)(e,y);return(0,o.jsx)("img",(0,r.Z)({style:{maxWidth:"80%",maxHeight:"60vh"}},t))},p:function(e){e.node;var t=(0,n.Z)(e,v);return(0,o.jsx)("p",(0,r.Z)({style:{margin:0}},t))}}})}function S(){return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)("small",{style:{display:"block",textAlign:"center"},children:["| under the supervision of ",(0,o.jsx)("i",{style:{color:"#1E90FF"},children:"italic"})," ; ",(0,o.jsx)("b",{children:"\u2020"})," indicates equal contribution |"]}),(0,o.jsx)(c,{}),(0,o.jsx)("br",{})]})}function I(){return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)("h2",{id:"researchStory",style:{"font-family":"BrushScriptMT-embed",textAlign:"center"},children:(0,o.jsx)("b",{children:"Journey Behind the Research"})}),a.map((function(e,t){return e.Journey&&(0,o.jsxs)("div",{children:[(0,o.jsx)(f.R,{title:(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)("b",{children:["About ",e.JourneyCategory]})," ",(0,o.jsx)("i",{children:e.ShortTitle||e.Title}),"."]}),mainText:(0,o.jsx)(C,{Journey:e.Journey})}),(0,o.jsx)("br",{})]})}))]})}function P(){return(0,p.useEffect)((function(){document.title="Research - Peter HU"}),[]),(0,o.jsxs)(d.E.div,{children:[(0,o.jsx)(l.Z,{}),(0,o.jsx)(u.Z,{}),(0,o.jsx)("h2",{id:"research",children:(0,o.jsx)("b",{children:"RESEARCH"})}),(0,o.jsx)("div",{class:"content",children:(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)("h2",{id:"academicResearch",children:(0,o.jsx)("b",{children:"Academia research"})}),(0,o.jsx)("i",{children:"May, 2024 - Present"})," | ",(0,o.jsx)("a",{href:"https://www.cam.ac.uk/",children:(0,o.jsx)("img",{width:"27",height:"24",src:"./asset/photo/Logo/Cam.png",alt:"Cambridge"})})," ",(0,o.jsx)("a",{href:"https://core-lab.io/",children:"Cambridge Open Reality and Visual AI (CORE) Lab"})," (",(0,o.jsx)("a",{href:"https://www.cl.cam.ac.uk/~aco41/",children:"Prof Cengiz \xd6ztireli"}),"), ",(0,o.jsx)("a",{href:"https://www.cst.cam.ac.uk/",children:"Dept. of Computer Science and Technology"}),"  ",(0,o.jsx)("br",{}),(0,o.jsx)("br",{}),(0,o.jsxs)("div",{style:{width:"90%",margin:"auto"},children:["I am privileged to undertake some interesting academic research explorations @",(0,o.jsx)("a",{href:"https://core-lab.io/",children:"Core Lab"})," at the intersection of Computer Graphics, Computer Vision and Machine Learning. During this period, I explore the neural representations of materials, physical accuracy, generative models with evaluation, real-world material synthesis, and many other.",(0,o.jsx)("br",{}),"My undergraduate research is supervised by ",(0,o.jsx)("a",{href:"https://chenliang-zhou.github.io/",children:"Chenliang Zhou"})," on generative machine learning and Dr ",(0,o.jsx)("a",{href:"https://asztr.github.io/",children:"Alejandro Sztrajman"})," on real-world materials and ",(0,o.jsx)("a",{href:"https://en.wikipedia.org/wiki/Bidirectional_reflectance_distribution_function",children:"Bidirectional Reflectance Distribution Function (BRDF)"}),"; mentored by Dr ",(0,o.jsx)("a",{href:"https://www.cl.cam.ac.uk/~fz261/",children:"Fangcheng Zhong"})," on Graphics (geometry representations and rendering), indoor layout synthesis.",(0,o.jsx)("br",{}),"I am honored to be the recipient of ",(0,o.jsx)("a",{href:"asset/doc/HuResearch20250327.pdf",children:"2025 Cambridge Summer Internship and Research Award"}),".",(0,o.jsx)("br",{})]}),(0,o.jsx)("br",{})," ",(0,o.jsx)("br",{}),(0,o.jsx)("br",{}),(0,o.jsx)("h2",{style:{"font-family":"BrushScriptMT-embed",textAlign:"center"},children:"List of Publications"}),(0,o.jsx)(S,{}),(0,o.jsx)("br",{}),(0,o.jsx)(I,{}),(0,o.jsx)("br",{}),(0,o.jsx)("h2",{id:"talk",style:{"font-family":"BrushScriptMT-embed",textAlign:"center"},children:(0,o.jsx)("b",{children:"Talk"})}),(0,o.jsx)(g.TalkRayTracing,{showall:!0}),(0,o.jsx)("br",{})," ",(0,o.jsx)("br",{}),(0,o.jsx)("h2",{id:"industryResearch",children:(0,o.jsx)("b",{children:"Industry research"})})]})}),(0,o.jsx)(g.ExperienceContents,{showall:!1}),(0,o.jsx)(h.Z,{})]})}},8641:function(e,t,i){i.d(t,{Z:function(){return h}});var r=i(7849),n=i(9439),a=i(2791),s=i(3495),o=i(184);function c(){var e=(0,a.useState)(0),t=(0,n.Z)(e,2),i=t[0],r=t[1],c=["\u0ca0_\u0ca0","(\u2022\u203f\u2022)","(\xac\u203f\xac)","(\u256f\xb0\u25a1\xb0)\u256f","\\(\xb0\u25a1\xb0)/"];return(0,a.useEffect)((function(){var e=setInterval((function(){r((function(e){return(e+1)%c.length}))}),8e3);return function(){return clearInterval(e)}}),[]),(0,o.jsx)("div",{style:{width:"80%",margin:"auto",textAlign:"center"},children:(0,o.jsxs)("div",{class:"announcement",children:["| ",(0,o.jsx)(s.fO,{to:"/",className:"project-link",children:"Home\ud83c\udfe0"}),"   /      ",(0,o.jsx)(s.fO,{to:"/aboutme",className:"project-link",children:"Bio.\ud83d\udc68\u200d\ud83d\udcbb"})," /  ",(0,o.jsx)(s.fO,{to:"/research",className:"project-link",children:"Research\ud83d\udcad"})," \\       ",(0,o.jsx)(s.fO,{to:"/award",className:"project-link",children:"Awards\ud83e\udd47"})," \\ ",(0,o.jsx)(s.fO,{to:"/project",className:"project-link",children:"Projects\ud83e\uddd1\u200d\ud83d\udcbb"})," | ",(0,o.jsx)("br",{}),(0,o.jsxs)("div",{style:{color:"gray"},children:["\ud83d\udc48 Alternatively, please navigate via the left sidebar. \u196b\u1b61 ",c[i]," \u196b\u1b61"]})]})})}function h(){return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(c,{}),(0,o.jsx)("hr",{width:"50%",color:"#C0C0C0",size:"1"}),(0,o.jsx)("table",{class:"table_footer",children:(0,o.jsx)("tbody",{children:(0,o.jsx)("td",{children:(0,o.jsx)(r.Z,{})})})})]})}},4136:function(e,t,i){i.d(t,{Z:function(){return d}});var r=i(9439),n=i(1087),a=i(3495),s=i(2791),o=i(7689),c=i(184);function h(){return-1===window.location.href.indexOf("project")?null:(0,c.jsxs)(c.Fragment,{children:[(0,c.jsxs)(a.fO,{id:"sidebar_visual",to:"/project/#Visual_Computing",children:["\xa0\xa0\xa0",(0,c.jsx)("i",{children:"visual"})]}),(0,c.jsxs)(a.fO,{id:"sidebar_ml",to:"/project/#Machine_Learning",children:["\xa0\xa0\xa0",(0,c.jsx)("i",{children:"AI/ML"})]}),(0,c.jsxs)(a.fO,{id:"sidebar_system",to:"/project/#Computer_System",children:["\xa0\xa0\xa0",(0,c.jsx)("i",{children:"system"})]}),(0,c.jsxs)(n.OL,{id:"sidebar_others",exact:!0,activeClassName:"is-active",to:"/project/others",children:["\xa0\xa0\xa0",(0,c.jsx)("i",{children:"others"})]})]})}function l(){return-1===window.location.href.indexOf("research")?null:(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)(a.fO,{id:"sidebar_academia",to:"/research/#academicResearch",children:(0,c.jsx)("i",{children:"\xa0\xa0\xa0academia"})}),(0,c.jsx)(a.fO,{id:"sidebar_publication",to:"/research/#pub",children:(0,c.jsx)("i",{children:"\xa0\xa0\xa0publication"})}),(0,c.jsx)(a.fO,{id:"sidebar_talk",to:"/research/#talk",children:(0,c.jsx)("i",{children:"\xa0\xa0\xa0talk"})}),(0,c.jsx)(a.fO,{id:"sidebar_industry",to:"/research/#industryResearch",children:(0,c.jsx)("i",{children:"\xa0\xa0\xa0industry"})})]})}function d(){var e=(0,s.useState)("\u2630sitemap"),t=(0,r.Z)(e,2),i=t[0],a=t[1],d=(0,s.useState)(!0),u=(0,r.Z)(d,2),p=u[0],g=u[1];(0,s.useEffect)((function(){var e=function(){window.innerWidth<800?(g(!1),a((0,c.jsx)("span",{style:{fontSize:"10px"},children:"\u25b8map"}))):(g(!0),a("\u2630sitemap"));var e=localStorage.getItem("showSidebar");if(null!==e){var t=JSON.parse(e);g(t),a(t?"\u2630sitemap":(0,c.jsx)("span",{style:{fontSize:"10px"},children:"\u25b8map"}))}};return e(),window.addEventListener("resize",e),function(){return window.removeEventListener("resize",e)}}),[]),(0,s.useEffect)((function(){localStorage.setItem("showSidebar",JSON.stringify(p))}),[p]);var f=(0,o.TH)(),x=["/","/aboutme","/research","/project","/award","/experience"],m=function(e){var t=x.indexOf(e);return-1===t?"/":x[(t-1+x.length)%x.length]}(f.pathname),j=function(e){var t=x.indexOf(e);return-1===t?"/":x[(t+1)%x.length]}(f.pathname);return(0,c.jsxs)("div",{id:"nav",class:"sidebar_main",children:[p&&(0,c.jsxs)("nav",{children:[(0,c.jsx)("span",{style:{flex:1,textAlign:"left"},children:(0,c.jsx)(n.OL,{to:m,children:"\u25c1Prev"})}),(0,c.jsx)("span",{style:{flex:1,textAlign:"right"},children:(0,c.jsx)(n.OL,{to:j,children:"\u27a4Next"})})]}),!p&&(0,c.jsxs)("nav",{children:[(0,c.jsx)(n.OL,{to:m,children:"\u25c1"}),(0,c.jsx)(n.OL,{to:j,children:"\u27a4"})]}),(0,c.jsx)("button",{className:"button ".concat(p?"button_sitemapon":"button_sitemapoff"),onClick:function(){g(!p)},onMouseOver:function(e){e.currentTarget.style.border="3px solid #A9A9A9",a(p?"\u2630CLOSE":"\u25b8EXPAND")},onMouseOut:function(e){e.currentTarget.style.border="",a(p?"\u2630sitemap":(0,c.jsx)("span",{style:{fontSize:"10px"},children:"\u25b8map"}))},children:i}),(0,c.jsx)("br",{}),p&&(0,c.jsxs)("nav",{children:[(0,c.jsx)(n.OL,{id:"sidebar_home",exact:!0,activeClassName:"is-active",to:"/",children:"\u25b8HOME"}),(0,c.jsx)(n.OL,{id:"sidebar_bio",exact:!0,activeClassName:"is-active",to:"/aboutme",children:"\u25b8Bio."}),(0,c.jsx)(n.OL,{id:"sidebar_pub",exact:!0,activeClassName:"is-active",to:"/research",children:"\u25b8Research"}),(0,c.jsx)(l,{}),(0,c.jsx)(n.OL,{id:"sidebar_project",exact:!0,activeClassName:"is-active",to:"/project",children:"\u25b8Projects"}),(0,c.jsx)(h,{}),(0,c.jsx)(n.OL,{id:"sidebar_award",exact:!0,activeClassName:"is-active",to:"/award",children:"\u25b8Awards"}),(0,c.jsx)("small",{children:(0,c.jsx)(n.OL,{id:"sidebar_exp",exact:!0,activeClassName:"is-active",to:"/experience",children:"\u25b8Experience"})})]})]})}}}]);
//# sourceMappingURL=680.da35b5e0.chunk.js.map